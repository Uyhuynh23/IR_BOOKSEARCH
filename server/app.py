import os
from flask import Flask, request, jsonify
from flask_cors import CORS
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, MatchText, Range
from sentence_transformers import SentenceTransformer, CrossEncoder

app = Flask(__name__)
CORS(app) # Cho ph√©p m·ªçi ngu·ªìn (Frontend React/Nextjs) g·ªçi API

# ==========================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==========================================
current_dir = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(current_dir, 'qdrant_db') 
COLLECTION_NAME = "books_hybrid"

# T√™n Model (S·∫Ω t·ª± t·∫£i v·ªÅ m√°y n·∫øu ch∆∞a c√≥)
BI_MODEL_NAME = 'all-MiniLM-L6-v2'
CROSS_MODEL_NAME = 'cross-encoder/ms-marco-MiniLM-L-6-v2'

print("‚è≥ ƒêang kh·ªüi ƒë·ªông Server...")

# ==========================================
# 2. K·∫æT N·ªêI DATABASE & AI MODELS
# ==========================================

# --- A. K·∫øt n·ªëi Qdrant Database ---
print(f"üìÇ ƒêang k·∫øt n·ªëi Qdrant t·∫°i: {DB_PATH}")

if os.path.exists(DB_PATH):
    client = QdrantClient(path=DB_PATH)
    # Ki·ªÉm tra ngay xem DB c√≥ d·ªØ li·ªáu kh√¥ng
    try:
        col_info = client.get_collection(COLLECTION_NAME)
        print(f"‚úÖ ƒê√£ t√¨m th·∫•y Collection '{COLLECTION_NAME}'")
        print(f"üìä S·ªë l∆∞·ª£ng vectors hi·ªán c√≥: {col_info.points_count}")
        
        if col_info.points_count == 0:
            print("‚ö†Ô∏è C·∫¢NH B√ÅO: K·∫øt n·ªëi th√†nh c√¥ng nh∆∞ng Database ƒëang R·ªñNG!")
    except Exception as e:
        print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t√¨m th·∫•y Collection '{COLLECTION_NAME}'.")
        print("üëâ G·ª£i √Ω: Ki·ªÉm tra xem file zip t·ª´ Kaggle ƒë√£ gi·∫£i n√©n ƒë√∫ng c·∫•u tr√∫c ch∆∞a.")
else:
    print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'qdrant_db'. ƒêang ch·∫°y ·ªü ch·∫ø ƒë·ªô RAM (s·∫Ω kh√¥ng c√≥ d·ªØ li·ªáu).")
    client = QdrantClient(":memory:") 

# --- B. Load Model AI ---
print("üß† ƒêang t·∫£i AI Models (L·∫ßn ƒë·∫ßu ch·∫°y s·∫Ω m·∫•t 1-2 ph√∫t)...")
try:
    bi_encoder = SentenceTransformer(BI_MODEL_NAME)
    cross_encoder = CrossEncoder(CROSS_MODEL_NAME)
    print("‚úÖ AI Models ƒë√£ s·∫µn s√†ng!")
except Exception as e:
    print(f"‚ùå L·ªói t·∫£i Model: {e}")

# ==========================================
# 3. C√îNG C·ª§ T·∫†O B·ªò L·ªåC (FILTER)
# ==========================================
def build_qdrant_filter(filters):
    """Chuy·ªÉn tham s·ªë t·ª´ URL th√†nh Qdrant Filter"""
    if not filters: return None
    
    must_conditions = []

    # 1. Genres (Th·ªÉ lo·∫°i)
    if filters.get('genres') and len(filters['genres']) > 0:
        should_conditions = []
        for genre in filters['genres']:
            should_conditions.append(
                FieldCondition(key="categories", match=MatchText(text=genre))
            )
        must_conditions.append(Filter(should=should_conditions))

    # 2. Author (T√°c gi·∫£)
    if filters.get('author'):
        must_conditions.append(
            FieldCondition(key="authors", match=MatchText(text=filters['author']))
        )

    # 3. NƒÉm xu·∫•t b·∫£n
    if filters.get('yearMin') or filters.get('yearMax'):
        range_params = {}
        if filters.get('yearMin'): range_params['gte'] = filters['yearMin']
        if filters.get('yearMax'): range_params['lte'] = filters['yearMax']
        must_conditions.append(
            FieldCondition(key="year", range=Range(**range_params))
        )

    # 4. ƒê√°nh gi√° (Rating)
    if filters.get('minRating'):
        must_conditions.append(
            FieldCondition(key="rating", range=Range(gte=filters['minRating']))
        )

    # 5. Ng√¥n ng·ªØ
    if filters.get('language') and filters['language'].lower() != 'all':
         must_conditions.append(
             FieldCondition(key="language", match=MatchValue(value=filters['language']))
         )

    if not must_conditions: return None
    return Filter(must=must_conditions)


# ==========================================
# 4. H√ÄM T√åM KI·∫æM CH√çNH (SEARCH ENGINE)
# ==========================================
def search_engine(query, top_k=20, filters=None):
    # B∆∞·ªõc 1: Encode Query -> Vector
    try:
        vector = bi_encoder.encode(query).tolist()
    except Exception as e:
        print(f"‚ùå L·ªói encode: {e}")
        return []

    # B∆∞·ªõc 2: Search Qdrant (Code t∆∞∆°ng th√≠ch m·ªçi version)
    q_filter = build_qdrant_filter(filters)
    
    try:
        # Ki·ªÉm tra xem client c√≥ h√†m 'search' m·ªõi kh√¥ng, n·∫øu kh√¥ng d√πng 'search_points'
        if hasattr(client, 'search'):
            search_result = client.search(
                collection_name=COLLECTION_NAME,
                query_vector=vector,
                query_filter=q_filter,
                limit=50
            )
        else:
            # FALLBACK: D√πng cho phi√™n b·∫£n c≈© h∆°n
            search_result = client.search_points(
                collection_name=COLLECTION_NAME,
                vector=vector,       # B·∫£n c≈© d√πng 'vector' thay v√¨ 'query_vector'
                filter=q_filter,     # B·∫£n c≈© d√πng 'filter' thay v√¨ 'query_filter'
                limit=50,
                with_payload=True
            )
    except Exception as e:
        print(f"‚ùå L·ªói Qdrant Search: {e}")
        # C·ªë g·∫Øng v·ªõt v√°t l·∫ßn cu·ªëi v·ªõi c√∫ ph√°p c·ªï ƒëi·ªÉn
        try:
             search_result, _ = client.scroll(
                collection_name=COLLECTION_NAME,
                scroll_filter=q_filter,
                limit=50
            )
        except:
            return []

    if not search_result:
        return []

    # B∆∞·ªõc 3: Chu·∫©n b·ªã d·ªØ li·ªáu cho Rerank
    candidates = []
    for hit in search_result:
        item = hit.payload
        # T·∫°o ƒëo·∫°n vƒÉn m√¥ t·∫£ ƒë·ªÉ AI ƒë·ªçc hi·ªÉu
        text_for_rerank = f"{item.get('title', '')} by {item.get('authors','')}. {item.get('description', '')[:300]}"
        
        candidates.append({
            'payload': item,
            'rerank_text': text_for_rerank
        })

    # B∆∞·ªõc 4: Reranking (Ch·∫•m ƒëi·ªÉm l·∫°i b·∫±ng Cross-Encoder)
    if not candidates: return []

    cross_inputs = [[query, c['rerank_text']] for c in candidates]
    cross_scores = cross_encoder.predict(cross_inputs)

    # G√°n ƒëi·ªÉm m·ªõi v√† chu·∫©n h√≥a t√™n field cho Frontend
    for i, candidate in enumerate(candidates):
        payload = candidate['payload']
        payload['score'] = float(cross_scores[i])
        
        # Chu·∫©n h√≥a c√°c field name ƒë·ªÉ match v·ªõi TypeScript interface
        if 'bookID' in payload and 'book_id' not in payload:
            payload['book_id'] = payload['bookID']
        
        # Map t·ª´ t√™n field trong DB -> t√™n field Frontend expect
        if 'rating' in payload:
            payload['average_rating'] = payload['rating']
        if 'year' in payload:
            payload['published_year'] = str(payload['year'])
        if 'categories' in payload:
            payload['google_category'] = payload['categories']

    # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo ƒëi·ªÉm m·ªõi
    ranked_results = sorted(candidates, key=lambda x: x['payload']['score'], reverse=True)

    # Tr·∫£ v·ªÅ Top K k·∫øt qu·∫£ t·ªët nh·∫•t
    return [x['payload'] for x in ranked_results[:top_k]]

# ==========================================
# 5. API ENDPOINTS
# ==========================================
@app.route('/search', methods=['GET'])
def search_endpoint():
    query = request.args.get('q', '').strip()
    
    # L·∫•y c√°c tham s·ªë filter t·ª´ URL
    filters = {}
    genres = request.args.get('genres', '')
    if genres and genres.lower() != 'all':
        filters['genres'] = [g.strip() for g in genres.split(',') if g.strip()]
    
    if request.args.get('author'): filters['author'] = request.args.get('author')
    
    try:
        if request.args.get('yearMin'): filters['yearMin'] = int(request.args.get('yearMin'))
        if request.args.get('yearMax'): filters['yearMax'] = int(request.args.get('yearMax'))
        if request.args.get('minRating'): filters['minRating'] = float(request.args.get('minRating'))
    except: pass

    lang = request.args.get('language', '')
    if lang: filters['language'] = lang

    try:
        # Allow search with filters only (empty query) if filters are provided
        if not query and not filters:
            return jsonify({"error": "Vui l√≤ng nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm ho·∫∑c ch·ªçn b·ªô l·ªçc"}), 400
        
        # If query is empty but filters exist, use a wildcard search
        search_query = query if query else "*"
        
        print(f"üîç ƒêang t√¨m: '{search_query}' | Filters: {filters}")
        results = search_engine(search_query, filters=filters)
        return jsonify(results)
    
    except Exception as e:
        print(f"‚ùå Server Error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/recommend', methods=['POST'])
def recommend_endpoint():
    data = request.json
    liked_ids = data.get('liked_ids', [])
    limit = data.get('limit', 10)
    valid_ids = [int(i) for i in liked_ids if str(i).isdigit()]

    if not valid_ids: 
        return jsonify([])

    try:
        # For each liked book ID, search for similar books
        all_recommendations = {}
        
        for book_id in valid_ids:
            try:
                # Use scroll with filter to find the specific book (much faster than scrolling all)
                scroll_result = client.scroll(
                    collection_name=COLLECTION_NAME,
                    scroll_filter=Filter(
                        should=[
                            FieldCondition(key="bookID", match=MatchValue(value=book_id)),
                            FieldCondition(key="book_id", match=MatchValue(value=book_id))
                        ]
                    ),
                    limit=1,
                    with_vectors=True
                )
                
                points = scroll_result[0]
                if not points or len(points) == 0:
                    print(f"‚ö†Ô∏è Book ID {book_id} not found in collection")
                    continue
                
                target_point = points[0]
                print(f"‚úÖ Found book {book_id} at Point ID: {target_point.id}")
                
                if not target_point.vector:
                    print(f"‚ö†Ô∏è Book ID {book_id} has no vector embedding")
                    continue
                
                # Search for similar books based on embedding using query_points
                try:
                    hits = client.query_points(
                        collection_name=COLLECTION_NAME,
                        query=target_point.vector,
                        limit=limit + 1,
                        score_threshold=0.3,  # Lower threshold for more results
                        with_payload=True
                    ).points
                    print(f"‚úÖ query_points returned {len(hits)} results")
                except Exception as e1:
                    print(f"‚ö†Ô∏è query_points failed: {e1}, trying search...")
                    try:
                        # Fallback: try search method
                        hits = client.search(
                            collection_name=COLLECTION_NAME,
                            query_vector=target_point.vector,
                            limit=limit + 1,
                            score_threshold=0.3
                        )
                        print(f"‚úÖ search returned {len(hits)} results")
                    except Exception as e2:
                        print(f"‚ùå Both methods failed: {e2}")
                        continue
                
                for hit in hits:
                    book_id_key = hit.payload.get('bookID') or hit.payload.get('book_id')
                    # Skip the book itself
                    if book_id_key != book_id:
                        payload = hit.payload
                        
                        # Normalize field names (same as search_engine)
                        if 'bookID' in payload and 'book_id' not in payload:
                            payload['book_id'] = payload['bookID']
                        
                        if 'rating' in payload and 'average_rating' not in payload:
                            payload['average_rating'] = payload['rating']
                        if 'year' in payload and 'published_year' not in payload:
                            payload['published_year'] = str(payload['year'])
                        if 'categories' in payload and 'google_category' not in payload:
                            payload['google_category'] = payload['categories']
                        
                        all_recommendations[book_id_key] = payload
            except Exception as e:
                print(f"‚ùå Error processing book {book_id}: {e}")
                continue
        
        result = list(all_recommendations.values())[:limit]
        print(f"üìö Returning {len(result)} recommendations")
        return jsonify(result)
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói Recommend: {e}")
        return jsonify([])

@app.route('/book/<int:book_id>', methods=['GET'])
def get_book_endpoint(book_id):
    """Get a single book by ID with all fields and field normalization"""
    try:
        # Use scroll with filter to find the specific book
        scroll_result = client.scroll(
            collection_name=COLLECTION_NAME,
            scroll_filter=Filter(
                should=[
                    FieldCondition(key="bookID", match=MatchValue(value=book_id)),
                    FieldCondition(key="book_id", match=MatchValue(value=book_id))
                ]
            ),
            limit=1,
            with_vectors=False  # Don't need vectors for detail view
        )
        
        points = scroll_result[0]
        if not points or len(points) == 0:
            print(f"‚ö†Ô∏è Book ID {book_id} not found")
            return jsonify(None), 404
        
        payload = points[0].payload
        
        # Normalize field names to match search_engine output
        if 'bookID' in payload and 'book_id' not in payload:
            payload['book_id'] = payload['bookID']
        
        # Map field names to match Frontend expectations (same as search_engine)
        if 'rating' in payload and 'average_rating' not in payload:
            payload['average_rating'] = payload['rating']
        if 'year' in payload and 'published_year' not in payload:
            payload['published_year'] = str(payload['year'])
        if 'categories' in payload and 'google_category' not in payload:
            payload['google_category'] = payload['categories']
        
        print(f"‚úÖ Fetched book {book_id}: {payload.get('title', 'Unknown')}")
        print(f"   Available fields: {list(payload.keys())}")
        return jsonify(payload)
    except Exception as e:
        print(f"‚ùå Error fetching book {book_id}: {e}")
        return jsonify(None), 500

if __name__ == '__main__':
    # üî• QUAN TR·ªåNG: Ch·∫°y port 5001 ƒë·ªÉ tr√°nh xung ƒë·ªôt tr√™n MacOS
    print("üöÄ SERVER ƒêANG CH·∫†Y T·∫†I: http://127.0.0.1:5001")
    app.run(port=5001, debug=True, use_reloader=False)